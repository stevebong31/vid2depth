{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting gen_data.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile gen_data.py\n",
    "# Copyright 2017 The TensorFlow Authors All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\n",
    "\"\"\"Generates data for training/validation and save it to disk.\"\"\"\n",
    "\n",
    "# Example usage:\n",
    "#\n",
    "# python dataset/gen_data.py \\\n",
    "#   --alsologtostderr \\\n",
    "#   --dataset_name kitti_raw_eigen \\\n",
    "#   --dataset_dir ~/vid2depth/dataset/kitti-raw-uncompressed \\\n",
    "#   --data_dir ~/vid2depth/data/kitti_raw_eigen_s3 \\\n",
    "#   --seq_length 3 \\\n",
    "#   --num_threads 12\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import itertools\n",
    "import multiprocessing\n",
    "import os\n",
    "from absl import app\n",
    "from absl import flags\n",
    "from absl import logging\n",
    "import dataset_loader\n",
    "import numpy as np\n",
    "import scipy.misc\n",
    "import tensorflow as tf\n",
    "\n",
    "gfile = tf.gfile\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "DATASETS = ['kitti_raw_eigen', 'kitti_raw_stereo', 'kitti_odom', 'cityscapes', 'bike', 'endo']\n",
    "\n",
    "flags.DEFINE_enum('dataset_name', None, DATASETS, 'Dataset name.')\n",
    "flags.DEFINE_string('dataset_dir', None, 'Location for dataset source files.')\n",
    "flags.DEFINE_string('data_dir', None, 'Where to save the generated data.')\n",
    "# Note: Training time grows linearly with sequence length.  Use 2 or 3.\n",
    "flags.DEFINE_integer('seq_length', 3, 'Length of each training sequence.')\n",
    "flags.DEFINE_integer('img_height', 256, 'Image height.')\n",
    "flags.DEFINE_integer('img_width', 256, 'Image width.')\n",
    "flags.DEFINE_integer(\n",
    "'num_threads', None, 'Number of worker threads. '\n",
    "    'Defaults to number of CPU cores.')\n",
    "\n",
    "flags.mark_flag_as_required('dataset_name')\n",
    "flags.mark_flag_as_required('dataset_dir')\n",
    "flags.mark_flag_as_required('data_dir')\n",
    "\n",
    "# Process data in chunks for reporting progress.\n",
    "NUM_CHUNKS = 100\n",
    "\n",
    "def _generate_data():\n",
    "    if not gfile.Exists(FLAGS.data_dir):\n",
    "        gfile.MakeDirs(FLAGS.data_dir)\n",
    "\n",
    "    global dataloader  # pylint: disable=global-variable-undefined\n",
    "    if FLAGS.dataset_name == 'bike':\n",
    "        dataloader = dataset_loader.Bike(FLAGS.dataset_dir,\n",
    "                                         img_height=FLAGS.img_height,\n",
    "                                         img_width=FLAGS.img_width,\n",
    "                                         seq_length=FLAGS.seq_length)\n",
    "    elif FLAGS.dataset_name == 'kitti_odom':\n",
    "        dataloader = dataset_loader.KittiOdom(FLAGS.dataset_dir,\n",
    "                                              img_height=FLAGS.img_height,\n",
    "                                              img_width=FLAGS.img_width,\n",
    "                                              seq_length=FLAGS.seq_length)\n",
    "    elif FLAGS.dataset_name == 'kitti_raw_eigen':\n",
    "        dataloader = dataset_loader.KittiRaw(FLAGS.dataset_dir,\n",
    "                                             split='eigen',\n",
    "                                             img_height=FLAGS.img_height,\n",
    "                                             img_width=FLAGS.img_width,\n",
    "                                             seq_length=FLAGS.seq_length)\n",
    "    elif FLAGS.dataset_name == 'kitti_raw_stereo':\n",
    "        dataloader = dataset_loader.KittiRaw(FLAGS.dataset_dir,\n",
    "                                             split='stereo',\n",
    "                                             img_height=FLAGS.img_height,\n",
    "                                             img_width=FLAGS.img_width,\n",
    "                                             seq_length=FLAGS.seq_length)\n",
    "    elif FLAGS.dataset_name == 'endo':\n",
    "        dataloader = dataset_loader.Endo(FLAGS.dataset_dir,\n",
    "                                         img_height=FLAGS.img_height,\n",
    "                                         img_width=FLAGS.img_width,\n",
    "                                         seq_length=FLAGS.seq_length)\n",
    "    else:\n",
    "        raise ValueError('Unknown dataset')\n",
    "\n",
    "  # The default loop below uses multiprocessing, which can make it difficult\n",
    "  # to locate source of errors in data loader classes.\n",
    "  # Uncomment this loop for easier debugging:\n",
    "\n",
    "  # all_examples = {}\n",
    "  # for i in range(dataloader.num_train):\n",
    "  #   _gen_example(i, all_examples)\n",
    "  #   logging.info('Generated: %d', len(all_examples))\n",
    "\n",
    "    all_frames = range(dataloader.num_train)\n",
    "    frame_chunks = np.array_split(all_frames, NUM_CHUNKS)\n",
    "\n",
    "    manager = multiprocessing.Manager()\n",
    "    all_examples = manager.dict()\n",
    "    num_cores = multiprocessing.cpu_count()\n",
    "    num_threads = num_cores if FLAGS.num_threads is None else FLAGS.num_threads\n",
    "    pool = multiprocessing.Pool(num_threads)\n",
    "\n",
    "  # Split into training/validation sets. Fixed seed for repeatability.\n",
    "    np.random.seed(8964)\n",
    "\n",
    "    if not gfile.Exists(FLAGS.data_dir):\n",
    "        gfile.MakeDirs(FLAGS.data_dir)\n",
    "\n",
    "    with gfile.Open(os.path.join(FLAGS.data_dir, 'train.txt'), 'w') as train_f:\n",
    "        with gfile.Open(os.path.join(FLAGS.data_dir, 'val.txt'), 'w') as val_f:\n",
    "            logging.info('Generating data...')\n",
    "            for index, frame_chunk in enumerate(frame_chunks):\n",
    "                all_examples.clear()\n",
    "                pool.map(_gen_example_star, itertools.izip(frame_chunk, itertools.repeat(all_examples)))\n",
    "                logging.info('Chunk %d/%d: saving %s entries...', index + 1, NUM_CHUNKS, len(all_examples))\n",
    "                for _, example in all_examples.items():\n",
    "                    if example:\n",
    "                        s = example['folder_name']\n",
    "                        frame = example['file_name']\n",
    "                        if np.random.random() < 0.1:\n",
    "                            val_f.write('%s %s\\n' % (s, frame))\n",
    "                        else:\n",
    "                            train_f.write('%s %s\\n' % (s, frame))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "\n",
    "def _gen_example(i, all_examples):\n",
    "    \"\"\"Saves one example to file.  Also adds it to all_examples dict.\"\"\"\n",
    "    example = dataloader.get_example_with_index(i)\n",
    "    if not example:\n",
    "        return\n",
    "    image_seq_stack = _stack_image_seq(example['image_seq'])\n",
    "    example.pop('image_seq', None)  # Free up memory.\n",
    "    intrinsics = example['intrinsics']\n",
    "    fx = intrinsics[0, 0]\n",
    "    fy = intrinsics[1, 1]\n",
    "    cx = intrinsics[0, 2]\n",
    "    cy = intrinsics[1, 2]\n",
    "    save_dir = os.path.join(FLAGS.data_dir, example['folder_name'])\n",
    "    if not gfile.Exists(save_dir):\n",
    "        gfile.MakeDirs(save_dir)\n",
    "    img_filepath = os.path.join(save_dir, '%s.jpg' % example['file_name'])\n",
    "    scipy.misc.imsave(img_filepath, image_seq_stack.astype(np.uint8))\n",
    "    cam_filepath = os.path.join(save_dir, '%s_cam.txt' % example['file_name'])\n",
    "    example['cam'] = '%f,0.,%f,0.,%f,%f,0.,0.,1.' % (fx, cx, fy, cy)\n",
    "    with open(cam_filepath, 'w') as cam_f:\n",
    "        cam_f.write(example['cam'])\n",
    "\n",
    "    key = example['folder_name'] + '_' + example['file_name']\n",
    "    all_examples[key] = example\n",
    "\n",
    "\n",
    "def _gen_example_star(params):\n",
    "    return _gen_example(*params)\n",
    "\n",
    "\n",
    "def _stack_image_seq(seq):\n",
    "    for i, im in enumerate(seq):\n",
    "        if i == 0:\n",
    "            res = im\n",
    "        else:\n",
    "            res = np.hstack((res, im))\n",
    "    return res\n",
    "\n",
    "\n",
    "def main(_):\n",
    "    _generate_data()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
